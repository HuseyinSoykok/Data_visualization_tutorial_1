{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bike-Share — Large CSV Exploration + Missing Values\n",
        "\n",
        "This notebook uses a synthetic dataset (Berlin, Munich, Hamburg) with ~120k trips.\n",
        "It demonstrates chunked CSV reading, data abstraction summaries, missing-values workflow, and simple plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install pandas matplotlib\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "pd.options.display.max_columns = 50\n",
        "USE_LOCAL_FILE = True\n",
        "LOCAL_PATH = Path('bikeshare_2024.csv')\n",
        "CHUNKSIZE = 25_000\n",
        "COLUMNS = ['trip_id','city','started_at','ended_at','start_station_id','end_station_id','start_lat','start_lng','end_lat','end_lng','user_type','bike_type','duration_s','distance_km','fare_eur']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chunked schema-ish summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "def chunk_reader():\n",
        "    return pd.read_csv(LOCAL_PATH, usecols=COLUMNS, chunksize=CHUNKSIZE, low_memory=False)\n",
        "\n",
        "n_rows=0; missing_counts=Counter()\n",
        "min_start=None; max_start=None\n",
        "lat_min=np.inf; lat_max=-np.inf; lng_min=np.inf; lng_max=-np.inf\n",
        "\n",
        "for chunk in chunk_reader():\n",
        "    n_rows += len(chunk)\n",
        "    for col in ['started_at','ended_at']:\n",
        "        chunk[col] = pd.to_datetime(chunk[col], errors='coerce')\n",
        "    missing_counts.update(chunk.isna().sum().to_dict())\n",
        "    if chunk['started_at'].notna().any():\n",
        "        cmin, cmax = chunk['started_at'].min(), chunk['started_at'].max()\n",
        "        min_start = cmin if (min_start is None or cmin < min_start) else min_start\n",
        "        max_start = cmax if (max_start is None or cmax > max_start) else max_start\n",
        "    if chunk['start_lat'].notna().any():\n",
        "        lat_min = min(lat_min, float(chunk['start_lat'].min()))\n",
        "        lat_max = max(lat_max, float(chunk['start_lat'].max()))\n",
        "    if chunk['start_lng'].notna().any():\n",
        "        lng_min = min(lng_min, float(chunk['start_lng'].min()))\n",
        "        lng_max = max(lng_max, float(chunk['start_lng'].max()))\n",
        "\n",
        "missing_pct = {k: (v / n_rows) * 100 for k, v in missing_counts.items()}\n",
        "print('Rows processed:', n_rows)\n",
        "print('Temporal coverage:', min_start, '→', max_start)\n",
        "print('Spatial extent (approx): lat', lat_min, 'to', lat_max, '; lng', lng_min, 'to', lng_max)\n",
        "print('Missing values (%):')\n",
        "missing_pct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build a working sample (~50k rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAMPLE_ROWS = 50_000\n",
        "sample=[]\n",
        "for chunk in pd.read_csv(LOCAL_PATH, usecols=COLUMNS, chunksize=CHUNKSIZE, low_memory=False):\n",
        "    for col in ['started_at','ended_at']:\n",
        "        chunk[col] = pd.to_datetime(chunk[col], errors='coerce')\n",
        "    sample.append(chunk)\n",
        "    if sum(len(s) for s in sample) >= SAMPLE_ROWS:\n",
        "        break\n",
        "df = pd.concat(sample, ignore_index=True).head(SAMPLE_ROWS)\n",
        "df.shape, df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324b00ab",
      "metadata": {},
      "source": [
        "## Helpful pandas function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81606bbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['bike_type'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a42f10d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['duration_s'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Missing-values workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "crit_mask = df['started_at'].notna()\n",
        "dfc = df.loc[crit_mask].copy()\n",
        "\n",
        "for c in dfc.columns:\n",
        "    dfc[c+'_was_missing'] = dfc[c].isna()\n",
        "dfc['hour_of_day'] = dfc['started_at'].dt.hour\n",
        "dfc['is_same_station'] = (dfc['start_station_id'] == dfc['end_station_id'])\n",
        "cat_cols = ['city','user_type','bike_type','start_station_id','end_station_id']\n",
        "\n",
        "for c in cat_cols:\n",
        "    if c in dfc:\n",
        "        mode = dfc[c].mode(dropna=True)\n",
        "        dfc[c] = dfc[c].fillna(mode.iloc[0] if not mode.empty else 'Unknown')\n",
        "\n",
        "for coord in ['start_lat','start_lng','end_lat','end_lng']:\n",
        "    if coord in dfc:\n",
        "        if 'city' in dfc:\n",
        "            dfc[coord] = dfc.groupby('city')[coord].transform(lambda s: s.fillna(s.median()))\n",
        "        dfc[coord] = dfc[coord].fillna(dfc[coord].median())\n",
        "\n",
        "dfc.loc[dfc['fare_eur'] < 0, 'fare_eur'] = np.nan\n",
        "dfc.loc[(dfc['duration_s'] <= 0) | (dfc['duration_s'] > 6*3600), 'duration_s'] = np.nan\n",
        "\n",
        "for c in ['duration_s','distance_km','fare_eur']:\n",
        "    if c in dfc:\n",
        "        dfc[c] = dfc[c].fillna(dfc[c].median())\n",
        "        \n",
        "dfc.isna().mean().sort_values(ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Quick plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(); dfc['distance_km'].clip(upper=dfc['distance_km'].quantile(0.99)).hist(bins=40)\n",
        "plt.title('Trip distance (km) — clipped 99th pct'); plt.xlabel('km'); plt.ylabel('count'); plt.show()\n",
        "plt.figure(); dfc['hour_of_day'].value_counts().sort_index().plot(kind='bar')\n",
        "plt.title('Trips by hour of day (sample)'); plt.xlabel('hour'); plt.ylabel('trips'); plt.show()\n",
        "plt.figure(); dfc.groupby('city')['fare_eur'].mean().sort_values().plot(kind='bar')\n",
        "plt.title('Average fare by city (sample)'); plt.xlabel('city'); plt.ylabel('fare_eur (avg)'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Export summaries & cleaned sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_col(s: pd.Series):\n",
        "    out = {'dtype': str(s.dtype), 'missing_pct': float(s.isna().mean()*100)}\n",
        "    if pd.api.types.is_datetime64_any_dtype(s):\n",
        "        out.update({'type':'temporal','min': s.min(), 'max': s.max()})\n",
        "    elif pd.api.types.is_numeric_dtype(s):\n",
        "        out.update({'type':'quantitative','min': float(np.nanmin(s)), 'max': float(np.nanmax(s))})\n",
        "    else:\n",
        "        out.update({'type':'categorical','unique': int(s.nunique(dropna=True))})\n",
        "    return out\n",
        "schema_rows = []\n",
        "for c in ['trip_id','city','started_at','ended_at','start_station_id','end_station_id','start_lat','start_lng','end_lat','end_lng','user_type','bike_type','duration_s','distance_km','fare_eur']:\n",
        "    if c in dfc:\n",
        "        schema_rows.append({'attribute': c, **summarize_col(dfc[c])})\n",
        "schema_df = pd.DataFrame(schema_rows)\n",
        "schema_df.to_csv('summary_bikeshare_sample.csv', index=False)\n",
        "dfc.to_csv('bikeshare_cleaned_sample.csv', index=False)\n",
        "\n",
        "schema_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38480de6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare series (coerce to string; keep a Missing bin)\n",
        "s = df.get(\"bike_type\", pd.Series(dtype=object)).astype(\"object\").fillna(\"Missing\")\n",
        "\n",
        "as_percent = False  # set True to plot percentages\n",
        "top_n = None        # set an int to cap categories shown, e.g., 10\n",
        "\n",
        "vc = s.value_counts(dropna=False)\n",
        "plot_data = (vc / len(s) * 100) if as_percent else vc\n",
        "if top_n:\n",
        "    plot_data = plot_data.head(top_n)\n",
        "\n",
        "# Quick text summary\n",
        "print(f\"bike_type — unique(non-missing)={df['bike_type'].nunique(dropna=True) if 'bike_type' in df else 0}, \"\n",
        "      f\"missing={(df['bike_type'].isna().mean()*100 if 'bike_type' in df else 0):.1f}%\")\n",
        "print(plot_data)\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plot_data.plot(kind=\"bar\")\n",
        "plt.title(f\"bike_type — {'%' if as_percent else 'count'} (n={len(s)})\")\n",
        "plt.xlabel(\"bike_type\")\n",
        "plt.ylabel(\"% of rows\" if as_percent else \"count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bundling",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
